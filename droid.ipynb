{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "db35ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c19316a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/nasa/team-space/nikita/data/droid/1.0.1/example/trajectory_im128.h5\"\n",
    "# filepath =\"tests/data/mimicgen/coffee.hdf5\"\n",
    "f = h5py.File(filepath, \"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f104f034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (200,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th></th></tr><tr><td>array[f64, 3]</td></tr></thead><tbody><tr><td>[-0.097429, 0.023944, 1.021375]</td></tr><tr><td>[-0.100067, 0.02024, 1.018641]</td></tr><tr><td>[-0.10186, 0.018697, 1.016557]</td></tr><tr><td>[-0.102355, 0.019562, 1.016142]</td></tr><tr><td>[-0.102256, 0.021384, 1.017054]</td></tr><tr><td>&hellip;</td></tr><tr><td>[-0.025469, 0.06101, 1.084676]</td></tr><tr><td>[-0.025872, 0.073872, 1.081445]</td></tr><tr><td>[-0.02698, 0.086011, 1.078382]</td></tr><tr><td>[-0.028219, 0.095188, 1.077276]</td></tr><tr><td>[-0.029627, 0.102016, 1.077866]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (200,)\n",
       "Series: '' [array[f64, 3]]\n",
       "[\n",
       "\t[-0.097429, 0.023944, 1.021375]\n",
       "\t[-0.100067, 0.02024, 1.018641]\n",
       "\t[-0.10186, 0.018697, 1.016557]\n",
       "\t[-0.102355, 0.019562, 1.016142]\n",
       "\t[-0.102256, 0.021384, 1.017054]\n",
       "\t…\n",
       "\t[-0.025469, 0.06101, 1.084676]\n",
       "\t[-0.025872, 0.073872, 1.081445]\n",
       "\t[-0.02698, 0.086011, 1.078382]\n",
       "\t[-0.028219, 0.095188, 1.077276]\n",
       "\t[-0.029627, 0.102016, 1.077866]\n",
       "]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.Series(values = f['data/demo_0/obs/robot0_eef_pos'][:], dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "16f19722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"gripper_position\": shape (320,), type \"<f8\">\n",
      "<HDF5 dataset \"cartesian_position\": shape (320, 6), type \"<f8\">\n",
      "<HDF5 dataset \"joint_positions\": shape (320, 7), type \"<f8\">\n",
      "<HDF5 dataset \"cartesian_position\": shape (320, 6), type \"<f8\">\n",
      "<HDF5 dataset \"cartesian_velocity\": shape (320, 6), type \"<f8\">\n",
      "<HDF5 dataset \"gripper_position\": shape (320, 1), type \"<f8\">\n",
      "<HDF5 dataset \"gripper_velocity\": shape (320, 1), type \"<f8\">\n",
      "<HDF5 dataset \"joint_position\": shape (320, 7), type \"<f8\">\n",
      "<HDF5 dataset \"joint_velocity\": shape (320, 7), type \"<f8\">\n"
     ]
    }
   ],
   "source": [
    "for field in [\n",
    "            \"observation/robot_state/gripper_position\",\n",
    "            \"observation/robot_state/cartesian_position\",\n",
    "            \"observation/robot_state/joint_positions\",\n",
    "            \"action/cartesian_position\",\n",
    "            \"action/cartesian_velocity\",\n",
    "            \"action/gripper_position\",\n",
    "            \"action/gripper_velocity\",\n",
    "            \"action/joint_position\",\n",
    "            \"action/joint_velocity\",\n",
    "]:\n",
    "    print(f[field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8f234918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (320,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th></th></tr><tr><td>array[u8, (128, 128, 3)]</td></tr></thead><tbody><tr><td>[[[0, 0, 0], [0, 0, 0], … [0, 0, 0]], [[0, 0, 0], [0, 0, 0], … [0, 0, 0]], … [[0, 0, 0], [0, 0, 0], … [0, 0, 0]]]</td></tr><tr><td>[[[0, 0, 0], [0, 0, 0], … [0, 0, 0]], [[0, 0, 0], [0, 0, 0], … [0, 0, 0]], … [[0, 0, 0], [0, 0, 0], … [0, 0, 0]]]</td></tr><tr><td>[[[0, 0, 0], [0, 0, 0], … [0, 0, 0]], [[0, 0, 0], [0, 0, 0], … [0, 0, 0]], … [[0, 0, 0], [0, 0, 0], … [0, 0, 0]]]</td></tr><tr><td>[[[0, 0, 0], [0, 0, 0], … [0, 0, 0]], [[0, 0, 0], [0, 0, 0], … [0, 0, 0]], … [[0, 0, 0], [0, 0, 0], … [0, 0, 0]]]</td></tr><tr><td>[[[0, 0, 0], [0, 0, 0], … [0, 0, 0]], [[0, 0, 0], [0, 0, 0], … [0, 0, 0]], … [[0, 0, 0], [0, 0, 0], … [0, 0, 0]]]</td></tr><tr><td>&hellip;</td></tr><tr><td>[[[0, 0, 0], [0, 0, 0], … [0, 0, 0]], [[0, 0, 0], [0, 0, 0], … [0, 0, 0]], … [[0, 0, 0], [0, 0, 0], … [0, 0, 0]]]</td></tr><tr><td>[[[0, 0, 0], [0, 0, 0], … [0, 0, 0]], [[0, 0, 0], [0, 0, 0], … [0, 0, 0]], … [[0, 0, 0], [0, 0, 0], … [0, 0, 0]]]</td></tr><tr><td>[[[0, 0, 0], [0, 0, 0], … [0, 0, 0]], [[0, 0, 0], [0, 0, 0], … [0, 0, 0]], … [[0, 0, 0], [0, 0, 0], … [0, 0, 0]]]</td></tr><tr><td>[[[0, 0, 0], [0, 0, 0], … [0, 0, 0]], [[0, 0, 0], [0, 0, 0], … [0, 0, 0]], … [[0, 0, 0], [0, 0, 0], … [0, 0, 0]]]</td></tr><tr><td>[[[0, 0, 0], [0, 0, 0], … [0, 0, 0]], [[0, 0, 0], [0, 0, 0], … [0, 0, 0]], … [[0, 0, 0], [0, 0, 0], … [0, 0, 0]]]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (320,)\n",
       "Series: '' [array[u8, (128, 128, 3)]]\n",
       "[\n",
       "\t[[[0, 0, 0], [0, 0, 0], … [0, 0, 0]], [[0, 0, 0], [0, 0, 0], … [0, 0, 0]], … [[0, 0, 0], [0, 0, 0], … [0, 0, 0]]]\n",
       "\t[[[0, 0, 0], [0, 0, 0], … [0, 0, 0]], [[0, 0, 0], [0, 0, 0], … [0, 0, 0]], … [[0, 0, 0], [0, 0, 0], … [0, 0, 0]]]\n",
       "\t[[[0, 0, 0], [0, 0, 0], … [0, 0, 0]], [[0, 0, 0], [0, 0, 0], … [0, 0, 0]], … [[0, 0, 0], [0, 0, 0], … [0, 0, 0]]]\n",
       "\t[[[0, 0, 0], [0, 0, 0], … [0, 0, 0]], [[0, 0, 0], [0, 0, 0], … [0, 0, 0]], … [[0, 0, 0], [0, 0, 0], … [0, 0, 0]]]\n",
       "\t[[[0, 0, 0], [0, 0, 0], … [0, 0, 0]], [[0, 0, 0], [0, 0, 0], … [0, 0, 0]], … [[0, 0, 0], [0, 0, 0], … [0, 0, 0]]]\n",
       "\t…\n",
       "\t[[[0, 0, 0], [0, 0, 0], … [0, 0, 0]], [[0, 0, 0], [0, 0, 0], … [0, 0, 0]], … [[0, 0, 0], [0, 0, 0], … [0, 0, 0]]]\n",
       "\t[[[0, 0, 0], [0, 0, 0], … [0, 0, 0]], [[0, 0, 0], [0, 0, 0], … [0, 0, 0]], … [[0, 0, 0], [0, 0, 0], … [0, 0, 0]]]\n",
       "\t[[[0, 0, 0], [0, 0, 0], … [0, 0, 0]], [[0, 0, 0], [0, 0, 0], … [0, 0, 0]], … [[0, 0, 0], [0, 0, 0], … [0, 0, 0]]]\n",
       "\t[[[0, 0, 0], [0, 0, 0], … [0, 0, 0]], [[0, 0, 0], [0, 0, 0], … [0, 0, 0]], … [[0, 0, 0], [0, 0, 0], … [0, 0, 0]]]\n",
       "\t[[[0, 0, 0], [0, 0, 0], … [0, 0, 0]], [[0, 0, 0], [0, 0, 0], … [0, 0, 0]], … [[0, 0, 0], [0, 0, 0], … [0, 0, 0]]]\n",
       "]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.Series(values=f['observation/camera/image/hand_camera_left_image'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7fc4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rbyte.io import Hdf5TensorSource\n",
    "\n",
    "Hdf5TensorSource(\"/nasa/team-space/nikita/data/droid/1.0.1/example/trajectory_im128.h5\", \"obs/agentview_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce27b86",
   "metadata": {},
   "outputs": [
    {
     "ename": "InstantiationException",
     "evalue": "Error in call to target 'rbyte.dataset.Dataset':\n5 validation errors for Dataset.__init__\nsamples.function-after[_validate(), PipelineInstanceConfig].inputs\n  Input should be an instance of Sequence [type=is_instance_of, input_value={'coffee/data/demo_0': {'...refix': '/data/demo_1'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineInstanceConfig].executor.is-instance[Executor]\n  Input should be an instance of Executor [type=is_instance_of, input_value={'_target_': 'concurrent....res.ThreadPoolExecutor'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineInstanceConfig].executor.`dict[union[str,tuple[str, ...]],is-instance[Executor]]`._target_\n  Input should be an instance of Executor [type=is_instance_of, input_value='concurrent.futures.ThreadPoolExecutor', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineInstanceConfig].pipeline\n  Input should be an instance of Pipeline [type=is_instance_of, input_value={'_target_': 'pipefunc.Pi...'method': 'vertical'}}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineHydraConfig].inputs\n  Input should be an instance of Sequence [type=is_instance_of, input_value={'coffee/data/demo_0': {'...refix': '/data/demo_1'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nfull_key: dataloader.dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rbyte/.venv/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:92\u001b[39m, in \u001b[36m_call_target\u001b[39m\u001b[34m(_target_, _partial_, args, kwargs, full_key)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_target_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rbyte/.venv/lib/python3.12/site-packages/pydantic/_internal/_validate_call.py:39\u001b[39m, in \u001b[36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(wrapped)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_function\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rbyte/.venv/lib/python3.12/site-packages/pydantic/_internal/_validate_call.py:136\u001b[39m, in \u001b[36mValidateCallWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mself\u001b[39m._create_validators()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[43m.\u001b[49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__:\n",
      "\u001b[31mValidationError\u001b[39m: 5 validation errors for Dataset.__init__\nsamples.function-after[_validate(), PipelineInstanceConfig].inputs\n  Input should be an instance of Sequence [type=is_instance_of, input_value={'coffee/data/demo_0': {'...refix': '/data/demo_1'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineInstanceConfig].executor.is-instance[Executor]\n  Input should be an instance of Executor [type=is_instance_of, input_value={'_target_': 'concurrent....res.ThreadPoolExecutor'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineInstanceConfig].executor.`dict[union[str,tuple[str, ...]],is-instance[Executor]]`._target_\n  Input should be an instance of Executor [type=is_instance_of, input_value='concurrent.futures.ThreadPoolExecutor', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineInstanceConfig].pipeline\n  Input should be an instance of Pipeline [type=is_instance_of, input_value={'_target_': 'pipefunc.Pi...'method': 'vertical'}}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineHydraConfig].inputs\n  Input should be an instance of Sequence [type=is_instance_of, input_value={'coffee/data/demo_0': {'...refix': '/data/demo_1'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mInstantiationException\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m initialize(version_base=\u001b[38;5;28;01mNone\u001b[39;00m, config_path=CONFIG_PATH):\n\u001b[32m     12\u001b[39m     cfg = compose(\n\u001b[32m     13\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mvisualize\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m         overrides=[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdataset=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASET\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m+data_dir=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m],\n\u001b[32m     15\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m dataloader = \u001b[43minstantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m batch = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(dataloader))\n\u001b[32m     21\u001b[39m batch\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rbyte/.venv/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:226\u001b[39m, in \u001b[36minstantiate\u001b[39m\u001b[34m(config, *args, **kwargs)\u001b[39m\n\u001b[32m    223\u001b[39m     _convert_ = config.pop(_Keys.CONVERT, ConvertMode.NONE)\n\u001b[32m    224\u001b[39m     _partial_ = config.pop(_Keys.PARTIAL, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstantiate_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_recursive_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_convert_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_partial_\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m OmegaConf.is_list(config):\n\u001b[32m    230\u001b[39m     \u001b[38;5;66;03m# Finalize config (convert targets to strings, merge with kwargs)\u001b[39;00m\n\u001b[32m    231\u001b[39m     config_copy = copy.deepcopy(config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rbyte/.venv/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:342\u001b[39m, in \u001b[36minstantiate_node\u001b[39m\u001b[34m(node, convert, recursive, partial, *args)\u001b[39m\n\u001b[32m    340\u001b[39m         value = node[key]\n\u001b[32m    341\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m recursive:\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m             value = \u001b[43minstantiate_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m                \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrecursive\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    345\u001b[39m         kwargs[key] = _convert_node(value, convert)\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _call_target(_target_, partial, args, kwargs, full_key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rbyte/.venv/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:347\u001b[39m, in \u001b[36minstantiate_node\u001b[39m\u001b[34m(node, convert, recursive, partial, *args)\u001b[39m\n\u001b[32m    342\u001b[39m                 value = instantiate_node(\n\u001b[32m    343\u001b[39m                     value, convert=convert, recursive=recursive\n\u001b[32m    344\u001b[39m                 )\n\u001b[32m    345\u001b[39m             kwargs[key] = _convert_node(value, convert)\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_target_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    349\u001b[39m     \u001b[38;5;66;03m# If ALL or PARTIAL non structured or OBJECT non structured,\u001b[39;00m\n\u001b[32m    350\u001b[39m     \u001b[38;5;66;03m# instantiate in dict and resolve interpolations eagerly.\u001b[39;00m\n\u001b[32m    351\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert == ConvertMode.ALL \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m    352\u001b[39m         convert \u001b[38;5;129;01min\u001b[39;00m (ConvertMode.PARTIAL, ConvertMode.OBJECT)\n\u001b[32m    353\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m node._metadata.object_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m    354\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rbyte/.venv/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:97\u001b[39m, in \u001b[36m_call_target\u001b[39m\u001b[34m(_target_, _partial_, args, kwargs, full_key)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m full_key:\n\u001b[32m     96\u001b[39m     msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mfull_key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m InstantiationException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mInstantiationException\u001b[39m: Error in call to target 'rbyte.dataset.Dataset':\n5 validation errors for Dataset.__init__\nsamples.function-after[_validate(), PipelineInstanceConfig].inputs\n  Input should be an instance of Sequence [type=is_instance_of, input_value={'coffee/data/demo_0': {'...refix': '/data/demo_1'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineInstanceConfig].executor.is-instance[Executor]\n  Input should be an instance of Executor [type=is_instance_of, input_value={'_target_': 'concurrent....res.ThreadPoolExecutor'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineInstanceConfig].executor.`dict[union[str,tuple[str, ...]],is-instance[Executor]]`._target_\n  Input should be an instance of Executor [type=is_instance_of, input_value='concurrent.futures.ThreadPoolExecutor', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineInstanceConfig].pipeline\n  Input should be an instance of Pipeline [type=is_instance_of, input_value={'_target_': 'pipefunc.Pi...'method': 'vertical'}}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineHydraConfig].inputs\n  Input should be an instance of Sequence [type=is_instance_of, input_value={'coffee/data/demo_0': {'...refix': '/data/demo_1'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nfull_key: dataloader.dataset"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "!j\n",
    "\n",
    "CONFIG_PATH = \"config\"\n",
    "DATA_DIR = Path.cwd().parent.resolve() / \"tests\" / \"data\" / \"mimicgen\"\n",
    "DATASET = \"mimicgen\"\n",
    "\n",
    "with initialize(version_base=None, config_path=CONFIG_PATH):\n",
    "    cfg = compose(\n",
    "        \"visualize\",\n",
    "        overrides=[f\"dataset={DATASET}\", f\"+data_dir={DATA_DIR}\"],\n",
    "    )\n",
    "\n",
    "\n",
    "dataloader = instantiate(cfg.dataloader)\n",
    "\n",
    "batch = next(iter(dataloader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7d26209",
   "metadata": {},
   "outputs": [
    {
     "ename": "InstantiationException",
     "evalue": "Error in call to target 'rbyte.dataset.Dataset':\n5 validation errors for Dataset.__init__\nsamples.function-after[_validate(), PipelineInstanceConfig].inputs\n  Input should be an instance of Sequence [type=is_instance_of, input_value={'coffee/data/demo_0': {'...refix': '/data/demo_1'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineInstanceConfig].executor.is-instance[Executor]\n  Input should be an instance of Executor [type=is_instance_of, input_value={'_target_': 'concurrent....res.ThreadPoolExecutor'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineInstanceConfig].executor.`dict[union[str,tuple[str, ...]],is-instance[Executor]]`._target_\n  Input should be an instance of Executor [type=is_instance_of, input_value='concurrent.futures.ThreadPoolExecutor', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineInstanceConfig].pipeline\n  Input should be an instance of Pipeline [type=is_instance_of, input_value={'_target_': 'pipefunc.Pi...'method': 'vertical'}}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineHydraConfig].inputs\n  Input should be an instance of Sequence [type=is_instance_of, input_value={'coffee/data/demo_0': {'...refix': '/data/demo_1'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nfull_key: dataloader.dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rbyte/.venv/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:92\u001b[39m, in \u001b[36m_call_target\u001b[39m\u001b[34m(_target_, _partial_, args, kwargs, full_key)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_target_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rbyte/.venv/lib/python3.12/site-packages/pydantic/_internal/_validate_call.py:39\u001b[39m, in \u001b[36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(wrapped)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_function\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rbyte/.venv/lib/python3.12/site-packages/pydantic/_internal/_validate_call.py:136\u001b[39m, in \u001b[36mValidateCallWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mself\u001b[39m._create_validators()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[43m.\u001b[49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__:\n",
      "\u001b[31mValidationError\u001b[39m: 5 validation errors for Dataset.__init__\nsamples.function-after[_validate(), PipelineInstanceConfig].inputs\n  Input should be an instance of Sequence [type=is_instance_of, input_value={'coffee/data/demo_0': {'...refix': '/data/demo_1'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineInstanceConfig].executor.is-instance[Executor]\n  Input should be an instance of Executor [type=is_instance_of, input_value={'_target_': 'concurrent....res.ThreadPoolExecutor'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineInstanceConfig].executor.`dict[union[str,tuple[str, ...]],is-instance[Executor]]`._target_\n  Input should be an instance of Executor [type=is_instance_of, input_value='concurrent.futures.ThreadPoolExecutor', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineInstanceConfig].pipeline\n  Input should be an instance of Pipeline [type=is_instance_of, input_value={'_target_': 'pipefunc.Pi...'method': 'vertical'}}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineHydraConfig].inputs\n  Input should be an instance of Sequence [type=is_instance_of, input_value={'coffee/data/demo_0': {'...refix': '/data/demo_1'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mInstantiationException\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dataloader = \u001b[43minstantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rbyte/.venv/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:226\u001b[39m, in \u001b[36minstantiate\u001b[39m\u001b[34m(config, *args, **kwargs)\u001b[39m\n\u001b[32m    223\u001b[39m     _convert_ = config.pop(_Keys.CONVERT, ConvertMode.NONE)\n\u001b[32m    224\u001b[39m     _partial_ = config.pop(_Keys.PARTIAL, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstantiate_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_recursive_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_convert_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_partial_\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m OmegaConf.is_list(config):\n\u001b[32m    230\u001b[39m     \u001b[38;5;66;03m# Finalize config (convert targets to strings, merge with kwargs)\u001b[39;00m\n\u001b[32m    231\u001b[39m     config_copy = copy.deepcopy(config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rbyte/.venv/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:342\u001b[39m, in \u001b[36minstantiate_node\u001b[39m\u001b[34m(node, convert, recursive, partial, *args)\u001b[39m\n\u001b[32m    340\u001b[39m         value = node[key]\n\u001b[32m    341\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m recursive:\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m             value = \u001b[43minstantiate_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m                \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrecursive\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    345\u001b[39m         kwargs[key] = _convert_node(value, convert)\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _call_target(_target_, partial, args, kwargs, full_key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rbyte/.venv/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:347\u001b[39m, in \u001b[36minstantiate_node\u001b[39m\u001b[34m(node, convert, recursive, partial, *args)\u001b[39m\n\u001b[32m    342\u001b[39m                 value = instantiate_node(\n\u001b[32m    343\u001b[39m                     value, convert=convert, recursive=recursive\n\u001b[32m    344\u001b[39m                 )\n\u001b[32m    345\u001b[39m             kwargs[key] = _convert_node(value, convert)\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_target_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    349\u001b[39m     \u001b[38;5;66;03m# If ALL or PARTIAL non structured or OBJECT non structured,\u001b[39;00m\n\u001b[32m    350\u001b[39m     \u001b[38;5;66;03m# instantiate in dict and resolve interpolations eagerly.\u001b[39;00m\n\u001b[32m    351\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert == ConvertMode.ALL \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m    352\u001b[39m         convert \u001b[38;5;129;01min\u001b[39;00m (ConvertMode.PARTIAL, ConvertMode.OBJECT)\n\u001b[32m    353\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m node._metadata.object_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m    354\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rbyte/.venv/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:97\u001b[39m, in \u001b[36m_call_target\u001b[39m\u001b[34m(_target_, _partial_, args, kwargs, full_key)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m full_key:\n\u001b[32m     96\u001b[39m     msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mfull_key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m InstantiationException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mInstantiationException\u001b[39m: Error in call to target 'rbyte.dataset.Dataset':\n5 validation errors for Dataset.__init__\nsamples.function-after[_validate(), PipelineInstanceConfig].inputs\n  Input should be an instance of Sequence [type=is_instance_of, input_value={'coffee/data/demo_0': {'...refix': '/data/demo_1'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineInstanceConfig].executor.is-instance[Executor]\n  Input should be an instance of Executor [type=is_instance_of, input_value={'_target_': 'concurrent....res.ThreadPoolExecutor'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineInstanceConfig].executor.`dict[union[str,tuple[str, ...]],is-instance[Executor]]`._target_\n  Input should be an instance of Executor [type=is_instance_of, input_value='concurrent.futures.ThreadPoolExecutor', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineInstanceConfig].pipeline\n  Input should be an instance of Pipeline [type=is_instance_of, input_value={'_target_': 'pipefunc.Pi...'method': 'vertical'}}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nsamples.function-after[_validate(), PipelineHydraConfig].inputs\n  Input should be an instance of Sequence [type=is_instance_of, input_value={'coffee/data/demo_0': {'...refix': '/data/demo_1'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\nfull_key: dataloader.dataset"
     ]
    }
   ],
   "source": [
    "dataloader = instantiate(cfg.dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
